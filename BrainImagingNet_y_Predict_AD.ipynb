{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCOwM1A2bi1ssbEQLlsmT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daonly/2024Spring/blob/main/BrainImagingNet_y_Predict_AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT4Amc2a4tsF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Predicting Alzheimers Disease (AD) status by Brain Image (preprocessed gray matter density/volume data)\n",
        "# Please preprocess your structural image to get the gray matter density data (wc1*) and gray matter volume data (mwc1*) by DPABI/DPARSF or SPM. The data required is NIfTI format (.nii or .nii.gz) in MNI space with a resolution of 91*109*91.\n",
        "# FORMAT python3 y_Predict_AD.py -i /in -o /out\n",
        "# /in -- the input dir, should be:\n",
        "#     1. The working dir of DPARSF (preprocessed by the DPARSF default parameter or DPARSF VBM parameter). There should be a 'T1ImgNewSegment' folder under this directory.\n",
        "#     2. Alternatively, can be a directory of preprocessed gray matter density data (wc1*) and gray matter volume data (mwc1*). Under this directory, there were filenames as wc1_XXXXX.nii and mwc1_XXXXX.nii (XXXXX is subject ID).\n",
        "# /out -- the output dir. There would be AD_Prediction.txt after prediction.\n",
        "# ___________________________________________________________________________\n",
        "# Written by YAN Chao-Gan 200710. Model credits also to Bin Lu and Zhi-Kai Chang.\n",
        "# International Big-Data Center for Depression Research, Institute of Psychology, Chinese Academy of Sciences, Beijing, China\n",
        "# ycg.yan@gmail.com\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from keras.optimizers import SGD, Adam\n",
        "import scipy.io as sio\n",
        "import tensorflow as tf\n",
        "from keras import layers, Input, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv3D, MaxPooling3D,AveragePooling3D, BatchNormalization\n",
        "from keras.models import load_model, Sequential\n",
        "from keras import models\n",
        "from keras import backend as K\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import multi_gpu_model\n",
        "import keras.callbacks\n",
        "\n",
        "\n",
        "def AD_Classifier(InputDir, OutputDir):\n",
        "\n",
        "    SegDir=glob.glob(InputDir+os.path.sep+'T1ImgNewSegment')\n",
        "\n",
        "    if len(SegDir)>=1:\n",
        "        SubList=[]\n",
        "        wc1FileList=[]\n",
        "        mwc1FileList=[]\n",
        "        FileList = os.listdir(InputDir+os.path.sep+'T1ImgNewSegment')\n",
        "        for iFile in range(len(FileList)):\n",
        "            SubList.append(FileList[iFile])\n",
        "            DirTemp=glob.glob(InputDir+os.path.sep+'T1ImgNewSegment'+os.path.sep+FileList[iFile]+os.path.sep+'wc1*')\n",
        "            wc1FileList.append(DirTemp[0])\n",
        "            DirTemp=glob.glob(InputDir+os.path.sep+'T1ImgNewSegment'+os.path.sep+FileList[iFile]+os.path.sep+'mwc1*')\n",
        "            mwc1FileList.append(DirTemp[0])\n",
        "    else:\n",
        "        SubList=[]\n",
        "        wc1FileList=[]\n",
        "        mwc1FileList=[]\n",
        "        DirTemp=glob.glob(InputDir+os.path.sep+'mwc1*')\n",
        "        for iFile in range(len(DirTemp)):\n",
        "            head_tail = os.path.split(DirTemp[iFile])\n",
        "            SubList.append(head_tail[1][4:-4])\n",
        "            wc1FileList.append(head_tail[0]+os.path.sep+head_tail[1][1:])\n",
        "            mwc1FileList.append(DirTemp[iFile])\n",
        "\n",
        "    Data_all = np.zeros(shape=(len(SubList),96,120,86,2),dtype=np.float16)\n",
        "    Mask = nib.load('Reslice_BrainMask_05_91x109x91.img')\n",
        "    Mask = Mask.get_data()\n",
        "    FullList = []\n",
        "    ShortList = []\n",
        "    for iSub in range(len(SubList)):\n",
        "        try:\n",
        "            wc1 = nib.load(wc1FileList[iSub])\n",
        "            mwc1 = nib.load(mwc1FileList[iSub])\n",
        "            FullList.append(iSub)\n",
        "        except FileNotFoundError:\n",
        "            ShortList.append(iSub)\n",
        "        wc1 = np.array(wc1.get_data()) * np.array(Mask)\n",
        "        mwc1 = np.array(mwc1.get_data()) * np.array(Mask)\n",
        "        Data_all[iSub,:,:,:,0] = wc1[12:108,13:133,16:102]\n",
        "        Data_all[iSub,:,:,:,1] = mwc1[12:108,13:133,16:102]\n",
        "    with tf.device('/cpu:0'):\n",
        "        Model0 = load_model('20210106_0_Phase4_Trans_AD_IncepResN_lr0003_Lfso_Fold0.h5')  #이게 key code다~\n",
        "        sgd = SGD(lr=0.001, decay=1e-4, momentum=0.9, nesterov=True)\n",
        "        Model0.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "        Prediction0 = Model0.predict(Data_all, batch_size=10)\n",
        "        Model1 = load_model('20210106_0_Phase4_Trans_AD_IncepResN_lr0003_Lfso_Fold1.h5')\n",
        "        sgd = SGD(lr=0.001, decay=1e-4, momentum=0.9, nesterov=True)\n",
        "        Model1.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "        Prediction1 = Model1.predict(Data_all, batch_size=10)\n",
        "        Model2 = load_model('20210106_0_Phase4_Trans_AD_IncepResN_lr0003_Lfso_Fold2.h5')\n",
        "        sgd = SGD(lr=0.001, decay=1e-4, momentum=0.9, nesterov=True)\n",
        "        Model2.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "        Prediction2 = Model2.predict(Data_all, batch_size=10)\n",
        "        Model3 = load_model('20210106_0_Phase4_Trans_AD_IncepResN_lr0003_Lfso_Fold3.h5')\n",
        "        sgd = SGD(lr=0.001, decay=1e-4, momentum=0.9, nesterov=True)\n",
        "        Model3.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "        Prediction3 = Model3.predict(Data_all, batch_size=10)\n",
        "        Model4 = load_model('20210106_0_Phase4_Trans_AD_IncepResN_lr0003_Lfso_Fold4.h5')\n",
        "        sgd = SGD(lr=0.001, decay=1e-4, momentum=0.9, nesterov=True)\n",
        "        Model4.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "        Prediction4 = Model4.predict(Data_all, batch_size=10)\n",
        "    Prediction=(Prediction0+Prediction1+Prediction2+Prediction3+Prediction4)/5\n",
        "\n",
        "    file_write_obj = open(OutputDir+'/AD_Prediction.txt', 'w')\n",
        "    for i in range(len(FullList)):\n",
        "        file_write_obj.write(SubList[FullList[i]]+':\\t'+str(Prediction[i])+' \\n')\n",
        "    file_write_obj.close()\n",
        "    file_write_obj = open(OutputDir+'/AD_Prediction.txt', 'a')\n",
        "    for i in range(len(ShortList)):\n",
        "        file_write_obj.write(SubList[ShortList[i]]+':\\tNaN\\n ')#    file_write_obj.write('Prediction Finished. If there is no result, please check the form of your input.')\n",
        "    file_write_obj.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='Predict AD')\n",
        "    parser.add_argument('-i', metavar='path', required=True,\n",
        "                        help='the path to input dir')\n",
        "    parser.add_argument('-o', metavar='path', required=True,\n",
        "                        help='the path to output dir')\n",
        "    args = parser.parse_args()\n",
        "    AD_Classifier(InputDir=args.i, OutputDir=args.o)"
      ]
    }
  ]
}